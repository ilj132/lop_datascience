{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Projeto LoP - DataScience.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "WUBAPloS58yP",
        "TjeHFDBfwV5w",
        "oPh-k3-fR_zP",
        "AEJF9bZMSZpk",
        "B4rJ_jPviRsl",
        "DmuLGrPKFv1c",
        "PGR1IWltjEKS",
        "7bW-MMNpvndY"
      ]
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3.9.0 64-bit",
      "metadata": {
        "interpreter": {
          "hash": "57e1db65e1cfa8678432bf177fe5d41003f42296b764486ff8a019a0e3141ba1"
        }
      }
    },
    "accelerator": "TPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YLxXyebtnjM-"
      },
      "source": [
        "\n",
        "\n",
        "# <center>Projeto LoP DataScience\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mVMECL1jJAxf"
      },
      "source": [
        "### Foi projetado para ter 4 tipos de consultas\n",
        "\n",
        "* A primeira é para receber dados dos professores que estão resgistrados no sistema\n",
        "\n",
        "* A segunda é para receber dados das turmas que estão registradas no sistema\n",
        "\n",
        "* A terceira é para receber dados das submissões que estão registradas no sistema\n",
        "\n",
        "* A quarta é para receber dados das questões que estão registradas no sistema\n",
        "\n",
        "As consultas vão ser tornando acumulativas, com a segunda dependendo de dados da primeira, e a terceira dependendo de dados da primeira e segunda para o preenchimento da url de consulta. Todas as consultas dependem da key de acesso\n",
        "\n",
        "Na consulta da class possui as depedências de: \n",
        "1. id_teacher, que é o id de um professor\n",
        "2. year, que é o ano da turma \n",
        "3. semester, que é o semestre (1 ou 2) da turma\n",
        "\n",
        "E na consulta de submission necessita do:\n",
        "1. id_class, que é o id de uma turma.\n",
        "\n",
        "Já a consulta de question e do teacher necessita apenas da key\n",
        "\n",
        "As consultas serão feitas via protocolo HTTP usando o método Get e irão receber um JSON dos dados do LoP\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "X2rVvODlKxFz"
      },
      "source": [
        "### Estrutra das funções e suas dependências\n",
        "\n",
        "Funções de coleta e transformações de dados \n",
        "\n",
        "- lop_class(), lop_question()\n",
        "--- lop_submission()\n",
        "------ question_data()\n",
        "--------- performance_list()\n",
        "------------ graph_more_less_70_list_class()\n",
        "------------ graph_distribution_notes_list()\n",
        "\n",
        "Funções de treinamento de modelos de Machine Learning"
      ]
    },
    {
      "source": [
        "### Descrição dos Dados\n",
        "#### <center> Dataframe Submissões\n",
        "| **Semestre** | **Número de atributos (colunas)** | **Número de Registros (linhas)** |\n",
        "| --- | --- | --- |\n",
        "| 2020.5 | xxxx | yyy |\n",
        "| 2020.6 | yyyy | xxx |\n",
        "\n",
        "#### <center>Dataframe Resultados em LOP\n",
        "| **Semestre** | **Número de atributos (colunas)** | **Número de Registros (linhas)** |\n",
        "| --- | --- | --- |\n",
        "| 2020.5 | xxxx | yyyyy |\n",
        "\n",
        "\n",
        "---\n",
        "\n",
        "#### Descrição do datafrane dos professores - Consulta embutida em lop_class()\n",
        "\n",
        "<b>1. id_teacher</b> ID do professor no LoP\n",
        "\n",
        "<b>2. email</b> Email do professor\n",
        "\n",
        "<b>3. name_teacher</b> Nome do professor\n",
        "\n",
        "--- \n",
        "\n",
        "#### Descrição do dataframe das turmas - lop_class()\n",
        "\n",
        "<b>1. id_teacher</b> ID do professor no LoP\n",
        "\n",
        "<b>2. id_class</b> ID da turma\n",
        "\n",
        "<b>3. name_class</b> Nome da turma\n",
        "\n",
        "<b>4. code</b> Código de acesso a turma no LoP\n",
        "\n",
        "<b>5. year</b> Ano em que a turma foi cadastrada\n",
        "\n",
        "<b>6. semester</b> Semestre em que a turma foi cadastrada\n",
        "\n",
        "---\n",
        "#### Descrição dos dataframe de Submissão - lop_submission()\n",
        "\n",
        "\n",
        "<b>1. environment</b> Tipo de máquina\n",
        "\n",
        "<b>2. hitPercentage</b> Porcentagem de acerto na questão\n",
        "\n",
        "<b>3. language</b> Linguagem de programação usada\n",
        "\n",
        "<b>4. char_change_number</b> Número de caracteres alterados\n",
        "\n",
        "<b>5. timeConsuming</b> Tempo que passou na questão\n",
        "\n",
        "<b>6. createdAt</b> Data e hora da submissão\n",
        "\n",
        "<b>7. user</b> Nome e matrícula do aluno\n",
        "\n",
        "<b>8. question</b> Nome da questão\n",
        "\n",
        "<b>9. list</b> Nome da lista\n",
        "\n",
        "<b>10. test</b> Nome da prova\n",
        "\n",
        "<b>11. id_class</b> ID da turma em que o aluno está associado nessa submissão\n",
        "\n",
        "---\n",
        "\n",
        "#### Descrição do dataframe das questões do LoP - lop_question()\n",
        "\n",
        "\n",
        "<b>1. id_questao</b> ID da questão\n",
        "\n",
        "<b>2. question</b> Nome da questão\n",
        "\n",
        "<b>3. difficulty </b> Nível de dificuldade da questão (1-5)\n",
        "\n",
        "<b>4. tags </b> Esse campo vem com um json que contem os assuntos em que essa questão está associada\n",
        "\n",
        "<b>5. lists </b> Esse campo vem com um json que contem as listas que a questão está associada \n",
        "\n",
        "<b>6. tests</b> Esse campo vem com um json que contem as provas que a questão está associada \n",
        "\n",
        "---\n",
        "\n",
        "#### Descrição do dataframe de dados das questões - question_data()\n",
        "\n",
        "\n",
        "<b>1. id_list</b> ID da lista\n",
        "\n",
        "<b>2. list</b> Nome da lista\n",
        "\n",
        "<b>3. question </b> Nome da questão\n",
        "\n",
        "<b>4. difficulty </b> Nível de dificuldade da questão (1-5)\n",
        "\n",
        "<b>5. tags </b> Em cada coluna com nome tag, terá um conteúdo associado a ela\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "#### Descrição do dataframe de performance por lista - performance_list()\n",
        "\n",
        "\n",
        "<b>1. user</b> Nome e matrícula do aluno\n",
        "\n",
        "<b>2. list</b> Nome da lista\n",
        "\n",
        "<b>3. totalHitPercentage </b> Soma de todos acertos de questões únicas\n",
        "\n",
        "<b>4. totalQuestionsList </b> Número de questões por lista\n",
        "\n",
        "<b>5. mediaList</b> Esse campo vem com um json que contem as provas que a questão está associada \n",
        "\n",
        "---"
      ],
      "cell_type": "markdown",
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "D_S-Ua3YeLmS"
      },
      "source": [
        "## 1. Importação das bibliotecas\n",
        "<a id='importacao'></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jauxgHcS9nOM"
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import json\n",
        "import urllib3\n",
        "urllib3.disable_warnings()\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "from datetime import datetime\n",
        "import re"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZGHrISEE_B3_"
      },
      "source": [
        "## 2. Funções\n",
        "<a id='funcoes'></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c8k5ZIKXkEJ_"
      },
      "source": [
        "Função de leitura de arquivos txt"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zgY9TfQvkCSh"
      },
      "source": [
        "def read_txt(path):\n",
        "  with open(path,'r') as file:\n",
        "    return file.read()"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1aRrmnVXkm82"
      },
      "source": [
        "Função de consulta no LoP"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BueEgapukKO8"
      },
      "source": [
        "def lop_consult(url):\n",
        "  http = urllib3.PoolManager()\n",
        "  req = http.request('GET',url)\n",
        "  if req.status == 200:\n",
        "    return pd.read_json(req.data, orient = 'RECORDS', encoding = 'utf-8').copy()\n",
        "  else: \n",
        "    return False"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zx_SDIJpLayi"
      },
      "source": [
        "Função para obter todas as classes do LoP a partir de uma lista de professores"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mbL2uxEK0X3M"
      },
      "source": [
        "def lop_class(df_teacher = pd.DataFrame()):\n",
        "  #Essa função se passar por cópia o df_teacher se torna desnecessário fazer a requisição de todas os professores, e evitando fazer varias consultas\n",
        "  #Dataframe onde será armazenado todas as turmas\n",
        "  df_class = pd.DataFrame()\n",
        "  if df_teacher.empty == True:\n",
        "    #Formação da url de consulta para saber os professores cadastrados no LoP\n",
        "    url_teacher = endpoint_teacher + key\n",
        "    #Realizando a consulta no LoP\n",
        "    df_teacher = lop_consult(url_teacher)#id, email, name\n",
        "  #O laço faz uma varredura das turmas de cada professor e por fim armazena em um dataframe de turmas\n",
        "  for id_teacher in df_teacher['id']:\n",
        "    #O LoP.v2 foi desenvolvido em 2019, então temos que capturar as turmas entre 2019 e o ano atual\n",
        "    current_year = datetime.now().year\n",
        "    for year in range(2019, current_year + 1):\n",
        "      #Por fim precisamos do semestre que deve ser 1 ou 2\n",
        "      for semester in range(1,3): \n",
        "        try:\n",
        "          #Url de consulta de classes\n",
        "          url_class = endpoint_class + id_teacher + '?year=' + str(year) + '&semester=' + str(semester) + '&key=' + key \n",
        "          #Dataframe provisório necessário para capturar o tamanho e saber quantas turmas esse professor tem que estar associado\n",
        "          df_prov = lop_consult(url_class)\n",
        "          #Inserindo o id do professor no dataframe de turmas\n",
        "          df_prov['id_teacher'] = id_teacher\n",
        "          #Adicionando turmas conforme novas consultas\n",
        "          df_class = df_class.append(df_prov, ignore_index=True).copy()#id, name, code, year, semester, id_teacher\n",
        "        except:\n",
        "          pass\n",
        "  #Renomeando colunas com nomes semelhantes em todos os DF\n",
        "  df_class.rename(columns={'id':'id_class','name':'name_class'}, inplace = True)\n",
        "  return df_class"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vVs1I-sChMaS"
      },
      "source": [
        "Função para obter todas as submissões a partir de uma lista de turmas"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9dqp3HGeFlKC"
      },
      "source": [
        "def lop_submission(df_class = pd.DataFrame()):\n",
        "  #Essa função se passar por cópia o df_class se torna desnecessário fazer a requisição de todas as turmas usando a função lop_class()\n",
        "  #Dataframe onde serão armazenados todas as submissões \n",
        "  df_submission = pd.DataFrame()  \n",
        "  if df_class.empty == True:\n",
        "    df_class = lop_class()  \n",
        "  #Obtem todas as submissões da lista de turmas passadas\n",
        "  for id_class in df_class['id_class']:\n",
        "    #Url da consulta as submissões\n",
        "    url_submission = endpoint_submission + id_class + '/submission?key=' + key\n",
        "    #Dataframe provisório que vai armazenar o resultado da consulta\n",
        "    df_prov = lop_consult(url_submission)\n",
        "    #Inserindo o id_class no dataframe de consultas\n",
        "    df_prov['id_class'] = id_class\n",
        "    #Adicionando submissões conforme consultas\n",
        "    df_submission = df_submission.append(df_prov, ignore_index=True).copy()\n",
        "  #Campo user trás matricula e o nome do usuário, vamos separar em 2 colunas distintas\n",
        "  df_submission[['user','registration']] = df_submission['user'].str.split('-',expand=True)\n",
        "  return df_submission"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aPYJVKnjA8jn"
      },
      "source": [
        "Função para obter dados das questões cadastradas no LoP"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OZu9CVgtA70_"
      },
      "source": [
        "def lop_question():\n",
        "  url_question = endpoint_question + key\n",
        "  df_lop_question = lop_consult(url_question)\n",
        "  df_lop_question.rename(columns = {'id':'id_question','title':'question'}, inplace = True)\n",
        "  return df_lop_question"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KbBdYtwVOXdZ"
      },
      "source": [
        "Função que transforma os dados das questões extraídas do LoP, assim podemos saber a dificuldade de uma questão, que pode estar associada a uma ou mais listas"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "J3pLjztaOWzR"
      },
      "source": [
        "def question_data(df_question = pd.DataFrame()):\n",
        "  #Essa função se passar por cópia o df_question se torna desnecessário fazer a requisição de todas as turmas usando a função lop_question()\n",
        "  #Dataframes onde serão armazenados todas as questões transformadas\n",
        "  df_list_data = pd.DataFrame() \n",
        "  df_test_data = pd.DataFrame() \n",
        "  df_tag_data = pd.DataFrame()  \n",
        "  df_question_data = pd.DataFrame()  \n",
        "  #i=0\n",
        "  if df_question.empty == True:\n",
        "    df_question = lop_question()\n",
        "  for question,lists,tests,tags,difficulty in zip(df_question['question'],df_question['lists'],df_question['tests'],df_question['tags'],df_question['difficulty']):\n",
        "    #Cada registro do json pode ficar com mais de uma lista associada a uma questão, por isso a necessidade de extrair\n",
        "    df_prov_lists  = pd.DataFrame(json.loads(str(lists).replace(\"'\",'\"')))\n",
        "    #Cada registro do json pode ficar com mais de uma lista associada a uma questão, por isso a necessidade de extrair\n",
        "    df_prov_tests  = pd.DataFrame(json.loads(str(tests).replace(\"'\",'\"')))\n",
        "    #df_prov_lists.rename(columns = {'id':'id_list','title':'list'}, inplace = True)\n",
        "    #Inserindo a questão associada\n",
        "    df_prov_lists['question'] = question\n",
        "    df_prov_lists['difficulty'] = difficulty\n",
        "    df_list_data = df_list_data.append(df_prov_lists, ignore_index = True).copy()\n",
        "    #print(df_list_data['question'])\n",
        "    #print(\"numero de questoes unicas no df \",len(df_list_data['question'].unique()))\n",
        "    df_prov_tests['question'] = question\n",
        "    df_prov_tests['difficulty'] = difficulty\n",
        "    df_test_data = df_test_data.append(df_prov_tests, ignore_index = True).copy()\n",
        "    #Extraindo as tags, que vão dizer o conteudo associado\n",
        "    df_prov_tags = pd.DataFrame(json.loads(str(tags).replace(\"'\",'\"'))).T\n",
        "    #Inserindo a questão associada\n",
        "    df_prov_tags['question'] = question    \n",
        "    df_tag_data = df_tag_data.append(df_prov_tags, ignore_index = True).copy()\n",
        "    #print(i,' ------------------  ',question, ' ',difficulty)\n",
        "    #i+=1\n",
        "    #if i == 100:\n",
        "    #  break\n",
        "  \n",
        "  df_list_data.rename(columns = {'id':'id_list','title':'list'}, inplace = True)\n",
        "  df_test_data.rename(columns = {'id':'id_test','title':'test'}, inplace = True)\n",
        "  #print(len(df_list_data['question'].unique()))\n",
        "  #df_list_data['difficulty'] = df_list_data['difficulty'].astype('int')\n",
        "  columns_tags = ['question']\n",
        "  for i in range(len(df_tag_data.columns)-1): columns_tags.append('tag'+str(i+1))\n",
        "  df_tag_data.columns = columns_tags\n",
        "  df_list_data = pd.merge(df_list_data, df_tag_data, on = 'question', how = 'outer')#.fillna(0)\n",
        "  df_test_data = pd.merge(df_test_data, df_tag_data, on = 'question', how = 'outer')#.fillna(0)\n",
        "  return  pd.concat([df_list_data, df_test_data],axis=0).copy()"
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "source": [
        "### 2.2. Funções referentes a lista"
      ],
      "cell_type": "markdown",
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jU4EIevUPzqH"
      },
      "source": [
        "Função para avaliar a perfomance por lista"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3B0Kx6BKPfK6"
      },
      "source": [
        "def performance_list(df_submission):  \n",
        "  #Essa função necessita receber as submissões de uma turma ---------- depois podemos incrementar essa função ao ter uma turma associada e agrupar por elas\n",
        "  #Me traz as porcentagens maximas de acerto por questão\n",
        "  df_performance_list = df_submission.groupby(['user','list','question'])['hitPercentage'].max().reset_index()\n",
        "  #Soma as porcentagens de uma lista unica\n",
        "  df_performance_list = df_performance_list.groupby(['user','list'])['hitPercentage'].sum().reset_index()\n",
        "  #Renomeando para melhorar entendimento\n",
        "  df_performance_list.rename(columns={'hitPercentage':'totalHitPercentage'}, inplace = True)\n",
        "  #Usando a função de dados de questão para ter informações sobre que questões estão associadas a lista\n",
        "  df_question_data = question_data()\n",
        "  #Agrupa por lista e questão para ter apenas uma questão de cada, a operação não importa muito, apenas existe para completar o agrupamento --------- pode ser uma boa trocar por drop_duplicates\n",
        "  df_question_data = df_question_data.groupby(['list','question'])['id_list'].count().reset_index()\n",
        "  #Conta quantas questões tem por lista\n",
        "  df_question_data = df_question_data.groupby(['list'])['question'].count().reset_index()\n",
        "  #Renomeando lista\n",
        "  df_question_data.rename(columns={'question':'totalQuestionsList'}, inplace = True)\n",
        "  #Merge\n",
        "  df_performance_list = df_performance_list.merge(df_question_data, on = 'list')\n",
        "  #Média de acerto por lista\n",
        "  df_performance_list['mediaList'] = df_performance_list['totalHitPercentage'] / df_performance_list['totalQuestionsList']\n",
        "  return df_performance_list"
      ],
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "R7lq048T5cvn"
      },
      "source": [
        "Função do gráfico de barras que, por lista, faz a contagem de quem fez mais e menos de 70% da lista. Necessita de passar a performance do aluno por lista"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "btbzysrv5cF6"
      },
      "source": [
        "def graph_more_less_70_list_class(df_performance_list):\n",
        "  #Aqui eu conto, por lista, quantos tiraram mais de 70% de acerto\n",
        "  df_more70 = df_performance_list[df_performance_list['mediaList'] >= 70.0].groupby('list')['mediaList'].count().reset_index(name='more70')\n",
        "  #E nesse conta quantos tiveram menos de 70%\n",
        "  df_less70 = df_performance_list[df_performance_list['mediaList'] < 70.0].groupby('list')['mediaList'].count().reset_index(name='less70')\n",
        "  #Aqui junta ambos os dataframes, usando o outer, que, se por acaso não tiver uma ocorrência de uma lista em um dos dataframes, mesmo assim eles vão ser adicionados, é união dos conjuntos\n",
        "  df_less_more_70 = pd.merge(df_more70, df_less70, on = 'list', how = 'outer')\n",
        "  #E, se caso acontecer a situação de um não existir, substituimos o nan por 0\n",
        "  df_less_more_70.replace(np.NaN, 0, inplace = True)\n",
        "  return df_less_more_70.to_json('df_less_more_70.json',force_ascii=False, orient='records') #############3 por hora essa função tamebm esta realizando downlaod"
      ],
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ibCTW9blyG0b"
      },
      "source": [
        "Função do grafico de distribuição de notas por lista. Necessita da performance do  "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xmX_TtzQALyR"
      },
      "source": [
        "def graph_distribution_notes_list(df_performance_list):\n",
        "  #Agrupa por lista, e conta as ocorrências\n",
        "  return df_performance_list.groupby('list')['mediaList'].apply(lambda group: group.values.tolist()).to_json('df_distribuition_notes_list.json',force_ascii=False,orient='index')"
      ],
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G1VoaP7uTjbf"
      },
      "source": [
        "def select_questions(df_question_data,listas_escolhidas,provas_escolhidas):\n",
        "  #Selecionando onde List não é NaN\n",
        "  df_prov1 = df_question_data.dropna(subset=['list'])#{}.fillna(0)\n",
        "  #Selecionando onde Test não é NaN\n",
        "  df_prov2 = df_question_data.dropna(subset=['test'])#.fillna(0)\n",
        "  #Concatenação para permitir um loc que busque em todas as instancias\n",
        "  pat1 = '|'.join(['({})'.format(re.escape(c)) for c in listas_escolhidas])\n",
        "  pat2 = '|'.join(['({})'.format(re.escape(c)) for c in provas_escolhidas])\n",
        "  #Busca\n",
        "  df_prov1 = df_prov1.loc[df_prov1['list'].str.contains(pat1)].copy()\n",
        "  df_prov2 = df_prov2.loc[df_prov2['test'].str.contains(pat2)].copy()\n",
        "  return pd.concat([df_prov1, df_prov2],axis=0).copy()"
      ],
      "execution_count": 20,
      "outputs": []
    },
    {
      "source": [
        "### 2.3. Funções referentes a dificuldade"
      ],
      "cell_type": "markdown",
      "metadata": {}
    },
    {
      "source": [
        "Função que faz o cálculo da performance dos alunos por dificuldade e retorna um dataframe. É necessário passar por parâmetro uma turma e uma variável bool com valor True(para Prova) ou False(para Lista)"
      ],
      "cell_type": "markdown",
      "metadata": {}
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {},
      "outputs": [],
      "source": [
        "def df_difficulty_performance (turma, prova = False):\n",
        "\n",
        "  df_submissions = lop_submission(pd.DataFrame(turma, columns = ['id_class'])) # carregando dados de submissões da turma\n",
        "  df_questions = select_questions(question_data(),listas_escolhidas,provas_escolhidas) # carregando dados de questões selecionadas\n",
        "  \n",
        "  if (prova): # filtro de provas\n",
        "    df_questions = df_questions.dropna(subset=['test']).fillna(0)\n",
        "  else:\n",
        "    df_questions = df_questions.dropna(subset=['list']).fillna(0)\n",
        "\n",
        "  df_geral = pd.merge(df_submissions,df_questions, on = \"question\", how = \"inner\") # juntando os dataframes de submissões e questões\n",
        "  df_difficulty_performance = df_geral.groupby(['user','registration','question','difficulty'])['hitPercentage'].max().reset_index()\n",
        "  df_difficulty_performance = df_difficulty_performance.groupby(['user','registration','difficulty'])['hitPercentage'].sum().reset_index()\n",
        "  df_difficulty_performance.rename(columns={'hitPercentage':'totalHitPercentage'},inplace = True)\n",
        "\n",
        "  df_questions = df_questions.groupby(['question','difficulty']).count().reset_index()\n",
        "  df_questions = df_questions.groupby(['difficulty'])['question'].count().reset_index()\n",
        "  df_questions.rename(columns={'question':'totalQuestions'},inplace=True)\n",
        "\n",
        "  df_difficulty_performance = addData(df_difficulty_performance, df_difficulty_performance['difficulty'].unique(), df_difficulty_performance['user'].unique()  )\n",
        "  df_difficulty_performance = df_difficulty_performance.merge(df_questions, on = 'difficulty', how = 'outer')\n",
        "  df_difficulty_performance.replace(np.NaN, 0 , inplace = True)\n",
        "  df_difficulty_performance['averageDifficulty'] = df_difficulty_performance['totalHitPercentage'] / df_difficulty_performance['totalQuestions']\n",
        "  df_difficulty_performance = df_difficulty_performance.sort_values(['user','difficulty'])\n",
        "\n",
        "  return df_difficulty_performance\n",
        "  "
      ]
    },
    {
      "source": [
        "Função que retorna o json de estudantes aprovados, reprovados e faltosos de todas as listas passadas pelo professor. É necessário passar por parâmetro uma turma, a nota esperada para aprovação e uma variável bool com valor True(para Prova) ou False(para Lista)"
      ],
      "cell_type": "markdown",
      "metadata": {}
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {},
      "outputs": [],
      "source": [
        "def graph_aprov (turma, nota_esperada, prova = False):\n",
        "\n",
        "  #carregando os dados que serão utilizados na construção desse json\n",
        "  df_class = lop_class()\n",
        "\n",
        "  if (prova):\n",
        "    performance_df = df_difficulty_performance(turma, True)\n",
        "  else:\n",
        "    performance_df = df_difficulty_performance(turma, False)\n",
        "\n",
        "  #pegando da coluna 'averageDifficulty' do dataframe performance_df todos os que estão com media acima de 'nota_esperada'\n",
        "  df_aprov = performance_df[performance_df['averageDifficulty']>=nota_esperada].groupby('difficulty')['averageDifficulty'].count().reset_index(name  = 'approved')\n",
        "  #pegando da coluna 'averageDifficulty' do dataframe performance_df todos os que estão com media abaixo de 'nota_esperada'\n",
        "  df_disaprov= performance_df[performance_df['averageDifficulty']<nota_esperada].groupby('difficulty')['averageDifficulty'].count().reset_index(name = 'disapproved')\n",
        "  #juntando os dataframes criados acima em um só, com base na coluna 'difficulty' e com o método 'outer' para não haver perda de dados\n",
        "  df_aprov_disaprov = pd.merge(df_aprov, df_disaprov, on='difficulty', how='outer')\n",
        "  #como o método 'outer' foi utilizado é necessário substituir os vazios por zero\n",
        "  df_aprov_disaprov.replace(np.NaN,0,inplace=True)\n",
        "  #ordenando as colunas do dataframe\n",
        "  df_aprov_disaprov = df_aprov_disaprov[['difficulty','approved','disapproved']]\n",
        "\n",
        "  #buscando em df_class o numero de alunos matriculado na turma\n",
        "  df_turma= df_class.query(\"id_class == {}\".format(turma))[[\"id_class\",\"studentsCount\"]].drop_duplicates().reset_index().drop('index',axis=1)\n",
        "  #armazenando em num_alunos o valor da primeira row de studentsCount, ou seja, o numero de alunos matriculados na turma\n",
        "  num_alunos = int(df_turma[\"studentsCount\"][0])\n",
        "  #criando a coluna 'faltosos' sendo a diferença de num_alunos com a soma dos aprovados e reprovados\n",
        "  df_aprov_disaprov['missing'] = num_alunos - (df_aprov_disaprov['approved'] + df_aprov_disaprov['disapproved'])\n",
        "\n",
        "  #transformando todo o dataframe em inteiro\n",
        "  df_aprov_disaprov = df_aprov_disaprov.astype(int)\n",
        "  #ordenando o dataframe pela coluna dificuldade\n",
        "  df_aprov_disaprov = df_aprov_disaprov.sort_values(by='difficulty')\n",
        "  #renomeando as dificuldades para strings\n",
        "  df_aprov_disaprov= df_aprov_disaprov.replace({'difficulty': {1:\"Muito Fácil\",2:\"Fácil\", 3:\"Médio\",4:\"Difícil\",5:\"Muito Difícil\"} })\n",
        "  return df_aprov_disaprov#.to_json('df_aprov_disaprov.json', force_ascii=False, orient='records')"
      ]
    },
    {
      "source": [
        "Função que retorna o json com as médias de cada aluno por dificuldade e também a média da turma naquela dificuldade especifica. É necessário a passagem por parâmetro de uma turma e uma variável bool com valor True(para Prova) ou False(para Lista)"
      ],
      "cell_type": "markdown",
      "metadata": {}
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {},
      "outputs": [],
      "source": [
        "def averagebyDifficulty (turma, prova=False):\n",
        "  if(prova):\n",
        "    performance_df = df_difficulty_performance(turma, True) \n",
        "  else:\n",
        "    performance_df = df_difficulty_performance(turma, False)\n",
        "\n",
        "  performance_df.drop(['totalHitPercentage','totalQuestions'],axis=1,inplace=True)\n",
        "\n",
        "  df_student_averagebyDifficulty = performance_df\n",
        "  df_mean = df_student_averagebyDifficulty.groupby(['difficulty'])['averageDifficulty'].mean().reset_index()\n",
        "  df_mean.rename(columns={'averageDifficulty':'classAverage'},inplace=True)\n",
        "  df_student_averagebyDifficulty = df_student_averagebyDifficulty.merge(df_mean, how='outer', on='difficulty')\n",
        "  df_student_averagebyDifficulty = df_student_averagebyDifficulty.sort_values(['user','difficulty'])\n",
        "  df_student_averagebyDifficulty.replace({'difficulty': {1:\"Muito Fácil\",2:\"Fácil\", 3:\"Médio\",4:\"Difícil\",5:\"Muito Difícil\"} }, inplace=True)\n",
        "  return df_student_averagebyDifficulty#.to_json('df_student_averagebyDifficulty.json', force_ascii=False, orient='records')"
      ]
    },
    {
      "source": [
        "Função que retorna o json com as média geral do aluno, referente a soma das médias que o aluno obteve em cada dificuldade sobre o número de dificuldades existentes. É necessário a passagem por parâmetro de uma turma e uma variável bool com valor True(para Prova) ou False(para Lista)"
      ],
      "cell_type": "markdown",
      "metadata": {}
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {},
      "outputs": [],
      "source": [
        "def averageAllDifficulty (turma, prova = False ):\n",
        "    \n",
        "    if (prova):\n",
        "        performance_df = df_difficulty_performance(turma, True)\n",
        "    else:\n",
        "        performance_df = df_difficulty_performance(turma, False)\n",
        "\n",
        "    performance_df.drop(['totalHitPercentage','totalQuestions'],axis=1,inplace=True)\n",
        "\n",
        "    df_allmean = performance_df.groupby(['user','registration','difficulty','averageDifficulty']).count().reset_index()\n",
        "    df_allmean = df_allmean.groupby(['user','registration'])['averageDifficulty'].mean().reset_index()\n",
        "    df_allmean.rename(columns={'averageDifficulty':'averageAllDifficulty'},inplace=True)\n",
        "    return df_allmean#.to_json('df_averageAllDifficulty.json', force_ascii=False, orient='records')"
      ]
    },
    {
      "source": [
        "### FUNÇÕES TEMPORÁRIAS"
      ],
      "cell_type": "markdown",
      "metadata": {}
    },
    {
      "source": [
        "Função para adicionar dados faltoso ao dataframe de performance por dificuldade"
      ],
      "cell_type": "markdown",
      "metadata": {}
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {},
      "outputs": [],
      "source": [
        "def addData (df_difficulty_performance, difficulties, students):\n",
        "  new_obs = pd.DataFrame()\n",
        "\n",
        "  for i in df_difficulty_performance.columns.tolist():\n",
        "    new_obs[i]= [np.nan]\n",
        "  \n",
        "  for student in students:\n",
        "    new_obs[\"user\"] = [student]\n",
        "    df_student = df_difficulty_performance[df_difficulty_performance[\"user\"] == student].reset_index().drop('index', axis=1)\n",
        "    diff_questions = list(set(df_student[\"difficulty\"].unique()) ^ set(difficulties))\n",
        "    \n",
        "    if len(diff_questions)>0:\n",
        "      try:\n",
        "        registration = df_student[\"registration\"].iloc[0]\n",
        "      except:\n",
        "        break\n",
        "      for difficulty in diff_questions:\n",
        "        new_obs[\"difficulty\"] = [difficulty]\n",
        "        new_obs[\"registration\"] = [registration]\n",
        "        df_difficulty_performance = df_difficulty_performance.append(new_obs, ignore_index = True)\n",
        "  return df_difficulty_performance"
      ]
    },
    {
      "source": [
        "Função de média ponderada por dificuldade"
      ],
      "cell_type": "markdown",
      "metadata": {}
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {},
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'subjects' is not defined",
          "traceback": [
            "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[1;32m<ipython-input-26-ee023a1234c3>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;31m# 3: Deve-se chamar a função da seguinte forma: graphWeightedAverage([df1.copy(),df2.copy()]). Caso não seja atribuido uma lista de pesos (ordered_weight_list = [x,y,z], se faz uma média aritmética.)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 5\u001b[1;33m \u001b[1;32mdef\u001b[0m \u001b[0mgraphWeightedAverage\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mordered_dfs_list\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mordered_weight_list\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0msubjects\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msubjects\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      6\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m   \u001b[0mnumber_of_dfs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mordered_dfs_list\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;31m# calcula o número de dfs passados em ordered_dfs_list\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
            "\u001b[1;31mNameError\u001b[0m: name 'subjects' is not defined"
          ]
        }
      ],
      "source": [
        "# 1: Assume-se que a coluna numérica de interesse p/ calcular a média é sempre a última, e não pode haver mais de uma coluna numérica de média no mesmo df.\n",
        "# 2: Assume-se que a variável \"ordered_dfs_list\" terá todos os seus dataframes se tratando da mesma coisa, e com as mesmas colunas.\n",
        "# 3: Deve-se chamar a função da seguinte forma: graphWeightedAverage([df1.copy(),df2.copy()]). Caso não seja atribuido uma lista de pesos (ordered_weight_list = [x,y,z], se faz uma média aritmética.)\n",
        "\n",
        "def graphWeightedAverage(ordered_dfs_list,ordered_weight_list=None,subjects=subjects.copy()):\n",
        "\n",
        "  number_of_dfs = len(ordered_dfs_list) # calcula o número de dfs passados em ordered_dfs_list\n",
        "\n",
        "  initial_column_names = ordered_dfs_list[0].columns.tolist() # armazena o nome das colunas no df antes de manipular\n",
        "  last_column_name = initial_column_names[-1] # armazena o nome da última coluna (que é a numérica de interesse p/ calcular a média)\n",
        "\n",
        "  # Etapa para checar se tá tudo ok com os pesos, e atribuir um valor default caso não tenha sido especificado\n",
        "  if ordered_weight_list == None:\n",
        "    ordered_weight_list = [0.5]*number_of_dfs # default\n",
        "  elif number_of_dfs != len(ordered_weight_list):\n",
        "      raise ValueError('Both lists must have the same length')\n",
        "      return\n",
        "\n",
        "  for i in range(0,number_of_dfs): # varrendo todos os dfs da lista (um for bem pequeno. Atualmente, apenas 2 loops)\n",
        "    if 'registration' in ordered_dfs_list[i].columns.tolist(): # etapa necessária para lidar com o problema do lop de conseguir inserir caractere na matricula\n",
        "      ordered_dfs_list[i][\"registration\"] = ordered_dfs_list[i][\"registration\"].astype(str)\n",
        "\n",
        "    #ordered_dfs_list[i][\"df_id\"] = i\n",
        "    ordered_dfs_list[i][\"weight\"] = ordered_weight_list[i] # atribui o respectivo peso para cada linha do df\n",
        "\n",
        "    if i < 1: # concatena todos os dfs da lista\n",
        "      df = ordered_dfs_list[0]\n",
        "    else:\n",
        "      df = pd.concat([df,ordered_dfs_list[i]])\n",
        "\n",
        "\n",
        "  df[last_column_name] = df[last_column_name] * df[\"weight\"] # multiplica a coluna de interesse pelo peso\n",
        "\n",
        "  #as etapas a seguir são necessárias para eliminar o problema de haver assuntos na lista de exercícios e não haver na lista de provas, por exemplo.\n",
        "  #desse modo, caso exista em um e não no outro, ignora-se o peso do elemento faltante no cálculo da média.\n",
        "  student_weight_list = df.groupby(initial_column_names[:-1])[\"weight\"].sum().reset_index().iloc[:,-1] \n",
        "  df = df.groupby(initial_column_names[:-1])[last_column_name].sum().reset_index()\n",
        "  df[last_column_name] = df[last_column_name]/student_weight_list\n",
        "\n",
        "  return df#.to_json(\"df_weighted_average_all_subjects.json\",force_ascii=False, orient='records')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dD1-lyVuizPA"
      },
      "source": [
        "## 3. Leitura da Base\n",
        "<a id='leiturabase'></a>\n",
        "### 3.1. Leitura de endpoints e key"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "syfUfm4xQz82"
      },
      "source": [
        "key = read_txt('key.txt')\n",
        "endpoint_teacher = read_txt('endpoint_teacher.txt')\n",
        "endpoint_class = read_txt('endpoint_class.txt')\n",
        "endpoint_submission = read_txt('endpoint_submission.txt')\n",
        "endpoint_question = read_txt('endpoint_question.txt')"
      ],
      "execution_count": 27,
      "outputs": []
    },
    {
      "source": [
        "## 4. Sandbox \n",
        "\n",
        "Nessa seção é feito uma exploração dos dados para criação de funções"
      ],
      "cell_type": "markdown",
      "metadata": {}
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TTdxLTcRTlnP"
      },
      "source": [
        "listas_escolhidas = ['Laboratório 01 - Expressões Aritméticas',\n",
        "\n",
        "'Aula - Introdução Expressões Aritiméticas',\n",
        "\n",
        "'Aula - Funções Aritméticas',\n",
        "\n",
        "'Treinamento - Expressões Aritméticas',\n",
        "\n",
        "'(Lop) Lista de Laboratório 2 - Estrutura de decisão',\n",
        "\n",
        "'(Lop) Estruturas de decisão - problemas sobre divisibilidade',\n",
        "\n",
        "'(Lop) Estruturas de decisão - Múltiplas decisões',\n",
        "\n",
        "'(Lop) Estruturas de decisão - Operadores Lógicos',\n",
        "\n",
        "'Repetição condicional - Lista Resolvida (LOP)',\n",
        "\n",
        "'Repetição condicional - Lista Prática (LOP)',\n",
        "\n",
        "'Repetição condicional - Lista de Exercícios (LOP)',\n",
        "\n",
        "'Repetição contada - Lista Resolvida (LOP)',\n",
        "\n",
        "'Repetição contada - Lista Prática (LOP)',\n",
        "\n",
        "'Repetição contada - Lista de Exercícios (LOP)',\n",
        "\n",
        "'Vetores - Lista Resolvida (LOP)',\n",
        "\n",
        "'Vetores - Lista de Exercícios (LOP)',\n",
        "\n",
        "'Vetores - Lista Prática (LOP)']\n",
        "\n",
        "provas_escolhidas = ['Prova LoP - Turma 05 - 2020.6']"
      ],
      "execution_count": 121,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2nRWOmQfg4I1"
      },
      "source": [
        "turma = ['f2dd7bef-5b5d-4cb3-9efa-aa8652af0605']"
      ],
      "execution_count": 122,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 123,
      "metadata": {},
      "outputs": [],
      "source": [
        "df_submission = lop_submission(pd.DataFrame(turma, columns = ['id_class']))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 124,
      "metadata": {},
      "outputs": [],
      "source": [
        "#df_submission"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 589
        },
        "id": "E1C4G4HsMSTN",
        "outputId": "5bbd55cd-eae8-4246-9e1d-313ab8323ab9"
      },
      "source": [
        "df_questions = select_questions(question_data(),listas_escolhidas,provas_escolhidas)"
      ],
      "execution_count": 125,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 126,
      "metadata": {},
      "outputs": [],
      "source": [
        "#df_questions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 127,
      "metadata": {},
      "outputs": [],
      "source": [
        "df_questionsCount = df_questions.groupby(['question','list']).count().reset_index()\n",
        "df_questionsCount = df_questionsCount.groupby(['list'])['question'].count().reset_index()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 128,
      "metadata": {},
      "outputs": [],
      "source": [
        "#df_questionsCount"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 129,
      "metadata": {},
      "outputs": [],
      "source": [
        "df_submission = df_submission.merge(df_questions[:][['question','difficulty','tag1']], on = 'question', how = 'inner')\n",
        "df_submission[:]['tag1'].replace(np.NaN, 'ASSUNTO_EM_BRANCO', inplace= True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 130,
      "metadata": {},
      "outputs": [],
      "source": [
        "df_submission['timeConsumingInMinutes'] = df_submission['timeConsuming']/(60*1000)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 131,
      "metadata": {},
      "outputs": [],
      "source": [
        "#df_submission[df_submission['timeConsumingInMinutes']>0].sort_values(by='timeConsuming')"
      ]
    },
    {
      "source": [
        "Pegando a data de submissão"
      ],
      "cell_type": "markdown",
      "metadata": {}
    },
    {
      "cell_type": "code",
      "execution_count": 132,
      "metadata": {},
      "outputs": [],
      "source": [
        "from datetime import datetime"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 133,
      "metadata": {},
      "outputs": [],
      "source": [
        "df_submission['createdAt'] = pd.to_datetime(df_submission['createdAt'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 134,
      "metadata": {},
      "outputs": [],
      "source": [
        "df_submission['dateSubmission'] = df_submission['createdAt'].dt.date"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 135,
      "metadata": {},
      "outputs": [],
      "source": [
        "#df_submission"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 136,
      "metadata": {},
      "outputs": [],
      "source": [
        "colunas = ['difficulty','question','dateSubmission']\n",
        "df_teste = df_submission[df_submission.timeConsuming>0][colunas].groupby(['question','difficulty']).nunique().reset_index()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 137,
      "metadata": {},
      "outputs": [],
      "source": [
        "#df_teste['meanDaysPerQuestion'] = round(df_teste['dateSubmission'] / df_teste ['question'],2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 138,
      "metadata": {},
      "outputs": [],
      "source": [
        "#df_teste.sort_values(by='difficulty')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 139,
      "metadata": {},
      "outputs": [],
      "source": [
        "#df_submission['dateSubmission'].drop_duplicates().value_counts().reset_index()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 140,
      "metadata": {},
      "outputs": [],
      "source": [
        "colunas = ['list','timeConsumingInMinutes','test']\n",
        "df_timeMean = df_submission[df_submission.timeConsumingInMinutes>0][colunas].groupby(['list']).mean().reset_index()\n",
        "df_timeMean2 = df_submission[df_submission.timeConsumingInMinutes>0][colunas].groupby(['test']).mean().reset_index()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 141,
      "metadata": {},
      "outputs": [],
      "source": [
        "df_timeMean['timeConsumingInMinutes'] = round(df_timeMean['timeConsumingInMinutes'],2)\n",
        "#df_timeMean"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 142,
      "metadata": {},
      "outputs": [],
      "source": [
        "df_timeMean2['timeConsumingInMinutes'] = round(df_timeMean2['timeConsumingInMinutes'],2)\n",
        "#df_timeMean2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 143,
      "metadata": {},
      "outputs": [],
      "source": [
        "#round(df_timeMean['timeConsumingInMinutes'].mean(),2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 144,
      "metadata": {},
      "outputs": [],
      "source": [
        "colunasDif = ['timeConsumingInMinutes','difficulty']\n",
        "df_timeAveragePerDifficulty = df_submission[df_submission.timeConsumingInMinutes>0][colunasDif].groupby(['difficulty']).mean().reset_index()\n",
        "df_timeAveragePerDifficulty = df_timeAveragePerDifficulty.replace({'difficulty': {1:\"Muito Fácil\", 2:\"Fácil\", 3:\"Médio\",4:\"Difícil\",5:\"Muito Difícil\"} })\n",
        "df_timeAveragePerDifficulty = round(df_timeAveragePerDifficulty,2)\n",
        "#df_timeAveragePerDifficulty"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 145,
      "metadata": {},
      "outputs": [],
      "source": [
        "colunasSubjects = ['timeConsumingInMinutes','tag1']\n",
        "df_timeAveragePerSubject = df_submission[df_submission.timeConsumingInMinutes>0][colunasSubjects].groupby(['tag1']).mean().reset_index()\n",
        "#df_timeAveragePerDifficulty.replace( 0, 'ASSUNTO_EM_BRANCO', inplace=True )\n",
        "#df_timeAveragePerDifficulty = df_timeAveragePerDifficulty.replace({'difficulty': {1:\"Muito Fácil\", 2:\"Fácil\", 3:\"Médio\",4:\"Difícil\",5:\"Muito Difícil\"} })\n",
        "df_timeAveragePerSubject = round(df_timeAveragePerSubject,2)\n",
        "#df_timeAveragePerSubject"
      ]
    }
  ]
}